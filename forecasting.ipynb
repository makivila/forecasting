{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53053c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "%pip install statsmodels\n",
    "%pip install sqlalchemy\n",
    "%pip install matplotlib\n",
    "%pip install sklearn\n",
    "! conda install -c conda-forge xgboost\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "import urllib\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выгрузка данных из базы\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "server = 'test' \n",
    "database = 'test_base' \n",
    "username = 'test_username' \n",
    "password = 'test_password' \n",
    "params = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};\"\n",
    "                           \"SERVER= \"+server+\";\"\n",
    "                           \"DATABASE=\"+database+\";\"\n",
    "                           \"UID=\"+username+\";\"\n",
    "                           \"PWD=\"+password+\";\"\n",
    "                          )\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))\n",
    "df = pd.read_sql(\"SELECT * FROM table_test1 order by date\", engine)\n",
    "df_test = pd.read_sql(\"SELECT * FROM table_test2 order by date\", engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84440800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразование текстовых данных в числовые для данных level3\n",
    "label_level3 = LabelEncoder()\n",
    "label_level3.fit(df['level3'])\n",
    "df['level3_lbl'] = label_level3.transform(df['level3'])\n",
    "df_test['level3_lbl'] = label_level3.transform(df_test['level3'])\n",
    "\n",
    "#Преобразование текстовых данных в числовые для данных level5\n",
    "label_level5 = LabelEncoder()\n",
    "label_level5.fit(df['level5'])\n",
    "df['level5_lbl'] = label_level5.transform(df['level5'])\n",
    "df_test['level5_lbl'] = label_level5.transform(df_test['level5'])\n",
    "\n",
    "#Преобразование текстовых данных в числовые для данных level4\n",
    "label_level4= LabelEncoder()\n",
    "label_level4.fit(df['level4'])\n",
    "df['level4_lbl'] = label_level4.transform(df['level4'])\n",
    "df_test['level4_lbl'] = label_level4.transform(df_test['level4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление пустых строк в тренировочной и тестовой выборках\n",
    "Train = df.dropna()\n",
    "Test = df_test.dropna()\n",
    "\n",
    "X_forecast = Test[:0]\n",
    "#Получаю уникальные значения level5\n",
    "level5_variants = Train.level5.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level5 in level5_variants:\n",
    "    X_train = Train[Train['level5']== level5].copy()\n",
    "    X_test = Test[Test['level5']== level5].copy()\n",
    "    Y_train = X_train['qty_all'].copy()\n",
    "\n",
    "    #Подготовка массивов\n",
    "    X_train_v = X_train[[\n",
    "    'avg', \n",
    "    'd_avg_price'\n",
    "    ]]\n",
    "    X_test_v = X_test[[ \n",
    "    'avg', \n",
    "    'd_avg_price'\n",
    "    ]]\n",
    "    \n",
    "    X_test_k = X_test[['level3_lbl','level4_lbl','level5_lbl','Shop','holiday','dw','m']].astype(str)\n",
    "    X_train_k = X_train[['level3_lbl','level4_lbl','level5_lbl','Shop','holiday','dw','m']].astype(str)\n",
    "\n",
    "    #Cтандартизируем диапазон функциональных возможностей входного набора данных\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_v)\n",
    "\n",
    "    X_train_v_sc = scaler.transform(X_train_v)\n",
    "    X_test_v_sc = scaler.transform(X_test_v)\n",
    "    #Еще преобразование данных для того, чтобы модель не запуталась,\n",
    "    #ложно предположив, что данные связаны порядком или иерархией, которого на самом деле нет\n",
    "    one = OneHotEncoder(sparse = False)\n",
    "    one.fit (X_train_k)\n",
    "    X_train_k_d = one.transform(X_train_k)\n",
    "    X_test_k_d = one.transform(X_test_k)\n",
    "    \n",
    "    #увеличение массива данных по горизонтали\n",
    "    X_train_all = np.hstack((X_train_v_sc, X_train_k_d))\n",
    "    X_test_all = np.hstack((X_test_v_sc, X_test_k_d))\n",
    "    \n",
    "    #опытным путем подбираем параметры для моделей\n",
    "    params = {\n",
    "              'min_child_weight':[4, 6, 8],\n",
    "              'learning_rate': [0.1],\n",
    "              'n_estimators': [40,50,60,80,100],\n",
    "              'max_depth': [ 4, 5, 6]\n",
    "             }\n",
    "    #Используем модель основанную на деревьях решения с методами градиентного бустинга\n",
    "    model = XGBRegressor (random_state=0)\n",
    "    #Используем хелпера, который подберет наилучшие параметры для модели\n",
    "    grid_search = GridSearchCV (\n",
    "                       estimator = model, \n",
    "                       param_grid = params,\n",
    "                       scoring = 'neg_mean_absolute_error', \n",
    "                       verbose = 1 )\n",
    "    grid_search.fit(X_train_all, Y_train) \n",
    "    #Прогнозирование\n",
    "    Y_pred = grid_search.predict(X_test_all)\n",
    "    #Заливка данных в столбец прогноза\n",
    "    X_test['forecast'] = Y_pred\n",
    "    X_forecast = pd.concat([X_forecast, X_test])\n",
    "#Заливка данных в базу\n",
    "X_forecast.to_sql('table_result', con = engine, if_exists = 'replace', chunksize = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
